# main.py â€“ PferdeWert API mit Claude + GPT Parallel-Bewertung
import os
import logging
from typing import Optional

from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI
import anthropic

import tiktoken  # Token-ZÃ¤hler

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Initialisierung & Konfiguration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

# API Keys
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
CLAUDE_KEY = os.getenv("ANTHROPIC_API_KEY")

# Model Settings
MODEL_ID = os.getenv("PW_MODEL", "gpt-4o")
CLAUDE_MODEL = os.getenv("CLAUDE_MODEL", "claude-sonnet-4-20250514")
USE_CLAUDE = os.getenv("USE_CLAUDE", "false").lower() == "true"

# Initialize clients
openai_client = OpenAI(api_key=OPENAI_KEY) if OPENAI_KEY else None
claude_client = anthropic.Anthropic(api_key=CLAUDE_KEY) if CLAUDE_KEY else None

# Token counting
ENC = tiktoken.encoding_for_model(MODEL_ID) if OPENAI_KEY else None
CTX_MAX = 128_000
MAX_COMPLETION = int(os.getenv("PFERDEWERT_MAX_COMPLETION", 800))

logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logging.info(f"OpenAI-key: {'âœ…' if OPENAI_KEY else 'âŒ'} | Claude-key: {'âœ…' if CLAUDE_KEY else 'âŒ'} | Model: {MODEL_ID} | Use Claude: {USE_CLAUDE}")

def tokens_in(msgs: list[dict]) -> int:
    """Hilfsfunktion: zÃ¤hlt Tokens in OpenAI-Messages."""
    if not ENC:
        return 0
    total = 0
    for m in msgs:
        total += 4  # fixer Overhead pro Message
        total += len(ENC.encode(m["content"]))
    return total + 2  # Abschluss-Tokens

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  System Prompts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Original GPT Prompt (fÃ¼r Vergleich)
GPT_SYSTEM_PROMPT = os.getenv(
    "SYSTEM_PROMPT",
    """Du bist **PferdeWert AI**, eine hochspezialisierte Expert:innen-KI fÃ¼r Markt- und Preisbewertungen von Sport- und Zuchtpferden.

**DEINE AUFGABE:** Erstelle eine professionelle, strukturierte Bewertung basierend auf den bereitgestellten Pferdedaten.

**AUSGABEFORMAT:**

### Zusammenfassung
[Kurze EinschÃ¤tzung des Pferdes in 2-3 SÃ¤tzen]

### Marktbewertung
**GeschÃ¤tzter Marktwert:** [X.XXX - X.XXX â‚¬]

[BegrÃ¼ndung der PreisschÃ¤tzung basierend auf Rasse, Alter, Ausbildung, etc.]

### Bewertungsfaktoren
- **Rasse & Abstammung:** [Bewertung]
- **Alter & Ausbildungsstand:** [Bewertung] 
- **Potenzial & Verwendung:** [Bewertung]

### Empfehlungen
- [Konkrete Handlungsempfehlungen]
- [Vermarktungshinweise]

**WICHTIG:** 
- Preise in Euro, realistisch fÃ¼r deutschen Markt
- BerÃ¼cksichtige aktuelle Markttrends
- BegrÃ¼nde alle EinschÃ¤tzungen sachlich"""
)

# Optimierter Claude Prompt (fÃ¼r Kunden)
CLAUDE_SYSTEM_PROMPT = """Du bist **PferdeWert AI**, eine hochspezialisierte Expert:innen-KI fÃ¼r Markt- und Preisbewertungen von Sport- und Zuchtpferden.

WICHTIG - SCHREIBSTIL:
Schreibe im Stil von ChatGPT/GPT-4o - das bedeutet:
- Emotional und verkaufsorientiert
- Verwende Begriffe wie "erheblich steigert", "hohes Wertpotenzial", "auÃŸergewÃ¶hnlich"
- Betone positive Aspekte mit starken Adjektiven
- Verwende Marketing-Sprache: "Bieterinteresse", "optimale PrÃ¤sentation", "starke TurnierprÃ¤senz"
- Beschreibe Vermarktungswege lebendig: "Auktion mit starkem Bieterinteresse"
- Nutze emotionale VerstÃ¤rker: "beeindruckend", "vielversprechend", "exzellent"

**AUSGABEFORMAT:**

### Zusammenfassung
[Kurze, emotionale EinschÃ¤tzung des Pferdes in 2-3 SÃ¤tzen mit positiven VerstÃ¤rkern]

### Marktbewertung
**GeschÃ¤tzter Marktwert:** [X.XXX - X.XXX â‚¬]

[BegrÃ¼ndung der PreisschÃ¤tzung mit emotionaler Sprache und Marktpotenzial]

### Bewertungsfaktoren
- **Rasse & Abstammung:** [Bewertung mit emotionalen Adjektiven]
- **Alter & Ausbildungsstand:** [Bewertung mit Potenzial-Betonung]
- **Potenzial & Verwendung:** [Bewertung mit Zukunftschancen]

### Empfehlungen
- [Konkrete Handlungsempfehlungen mit verkaufsorientierten Formulierungen]
- [Vermarktungshinweise mit "optimaler PrÃ¤sentation" und "Bieterinteresse"]

**WICHTIG:** 
- Preise in Euro, realistisch fÃ¼r deutschen Markt
- BerÃ¼cksichtige aktuelle Markttrends
- Verwende emotionale, verkaufsorientierte Sprache
- Betone immer das Potenzial und positive Aspekte"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  FastAPI-App
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(title="PferdeWert API", version="0.7.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://pferdewert.vercel.app",
        "https://organic-sniffle-jjg7466rj9vvhqj7-3000.app.github.dev",
        "https://organic-sniffle-jjg7466rj9vvhqj7.github.dev"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Request-Schema
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class BewertungRequest(BaseModel):
    # Pflichtfelder
    rasse: str
    alter: int
    geschlecht: str
    abstammung: str
    stockmass: int
    ausbildung: str

    # Optionale Angaben
    aku: Optional[str] = None
    erfolge: Optional[str] = None
    farbe: Optional[str] = None
    zuechter: Optional[str] = None
    standort: Optional[str] = None
    verwendungszweck: Optional[str] = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  AI Bewertung (Claude + GPT parallel)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ai_valuation(d: BewertungRequest) -> str:
    """Hauptfunktion: Claude fÃ¼r Kunde, GPT parallel fÃ¼r Vergleich"""
    
    user_prompt = (
        f"Rasse: {d.rasse}\nAlter: {d.alter}\nGeschlecht: {d.geschlecht}\n"
        f"Abstammung: {d.abstammung}\nStockmaÃŸ: {d.stockmass} cm\n"
        f"Ausbildungsstand: {d.ausbildung}\n"
        f"Farbe: {d.farbe or 'k. A.'}\n"
        f"ZÃ¼chter / Ausbildungsstall: {d.zuechter or 'k. A.'}\n"
        f"Aktueller Standort (PLZ): {d.standort or 'k. A.'}\n"
        f"Verwendungszweck / Zielsetzung: {d.verwendungszweck or 'k. A.'}\n"
        f"Gesundheitsstatus / AKU-Bericht: {d.aku or 'k. A.'}\n"
        f"Erfolge: {d.erfolge or 'k. A.'}"
    )
    
    claude_result = None
    gpt_result = None
    
    # 1. Claude fÃ¼r Kunde (Hauptergebnis)
    if USE_CLAUDE and claude_client:
        try:
            logging.info("Prompt wird an Claude gesendet...")
            response = claude_client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=1000,
                temperature=0.0,  # FÃ¼r maximale Konsistenz
                system=CLAUDE_SYSTEM_PROMPT,
                messages=[{"role": "user", "content": user_prompt}]
            )
            
            # Robustes Parsing der Claude-Antwort
            if response.content and response.content[0].text:
                claude_result = response.content[0].text.strip()
                logging.info("âœ… Claude-Bewertung erfolgreich erstellt")
            else:
                raise ValueError("Claude-Antwort hat kein lesbares Textfeld")
                
        except Exception as e:
            logging.error(f"âŒ Claude Error: {e} - Fallback zu OpenAI")
    
    # 2. GPT parallel fÃ¼r Vergleich (lÃ¤uft immer wenn verfÃ¼gbar)
    if openai_client:
        try:
            logging.info("Prompt wird parallel an GPT gesendet...")
            messages = [
                {"role": "system", "content": GPT_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ]
            
            rsp = openai_client.chat.completions.create(
                model=MODEL_ID,
                messages=messages,
                temperature=0.0,  # Auch GPT konsistent machen
                top_p=0.8,
                seed=12345,  # Reproduzierbarkeit
                max_tokens=min(MAX_COMPLETION, CTX_MAX - tokens_in(messages)),
            )
            gpt_result = rsp.choices[0].message.content.strip()
            logging.info("âœ… GPT-Bewertung fÃ¼r Vergleich erstellt")
        except Exception as e:
            logging.error(f"âŒ GPT Error: {e}")
    
    # 3. GPT-Vergleich per E-Mail senden (wenn beide verfÃ¼gbar)
    if gpt_result:
        # send_gpt_comparison_mail(d, gpt_result)  # TemporÃ¤r deaktiviert
        logging.info("ğŸ“§ GPT-Vergleichsmail temporÃ¤r deaktiviert")
    
    # 4. Ergebnis zurÃ¼ckgeben: Claude bevorzugt, GPT als Fallback
    if claude_result:
        logging.info("âœ… Claude-Ergebnis wird an Kunde gesendet")
        return claude_result
    elif gpt_result:
        logging.info("âš ï¸ Claude nicht verfÃ¼gbar - GPT-Fallback wird an Kunde gesendet")
        return gpt_result
    else:
        logging.error("âŒ Beide AI-Services nicht verfÃ¼gbar")
        return (
            "Wir arbeiten gerade an unserem KI-Modell, "
            "bitte schicke uns eine E-Mail an info@pferdewert.de "
            "und wir melden uns, sobald das Modell wieder online ist."
        )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  API-Endpoint
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/api/bewertung")
def bewertung(req: BewertungRequest):
    logging.info(f"Incoming Request: {req.dict()}")
    try:
        ai_text = ai_valuation(req)
        return {"raw_gpt": ai_text}  # Key-Name bleibt fÃ¼r Frontend-KompatibilitÃ¤t
    except Exception as e:
        logging.error(f"AI-Error: {e}")
        return {
            "raw_gpt": (
                "Wir arbeiten gerade an unserem KI-Modell, "
                "bitte schicke uns eine E-Mail an info@pferdewert.de "
                "und wir melden uns, sobald das Modell wieder online ist."
            )
        }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Health Check
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/health")
def health_check():
    return {
        "status": "ok",
        "openai_available": bool(openai_client),
        "claude_available": bool(claude_client),
        "claude_model": CLAUDE_MODEL,
        "openai_model": MODEL_ID,
        "use_claude": USE_CLAUDE,
    }