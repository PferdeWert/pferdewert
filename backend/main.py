# main.py â€“ PferdeWert API mit Claude + GPT Parallel-Bewertung
import os
import logging
from typing import Optional

from dotenv import load_dotenv
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import OpenAI
import anthropic

import tiktoken  # Token-ZÃ¤hler

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Initialisierung & Konfiguration
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

# API Keys
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
CLAUDE_KEY = os.getenv("ANTHROPIC_API_KEY")

# Model Settings
MODEL_ID = os.getenv("PW_MODEL", "gpt-4o")
CLAUDE_SONNET_MODEL = "claude-sonnet-4-20250514"
CLAUDE_OPUS_MODEL = "claude-opus-4-1-20250805"
CLAUDE_MODEL = os.getenv("CLAUDE_MODEL", CLAUDE_OPUS_MODEL)  # Default to Opus
# Force Claude usage for testing in staging
USE_CLAUDE = os.getenv("USE_CLAUDE", "true").lower() == "true"  # Default to true for testing

# Initialize clients
openai_client = OpenAI(api_key=OPENAI_KEY) if OPENAI_KEY else None
claude_client = anthropic.Anthropic(api_key=CLAUDE_KEY) if CLAUDE_KEY else None

# Token counting
def get_tokenizer(model_id: str):
    """Get tokenizer for model, with fallback for newer models like GPT-5."""
    try:
        return tiktoken.encoding_for_model(model_id)
    except KeyError:
        # Fallback for newer models (GPT-5, etc.) - use GPT-4 tokenizer
        if model_id.startswith("gpt-5"):
            return tiktoken.encoding_for_model("gpt-4")
        # For other unknown models, use a safe default
        return tiktoken.get_encoding("cl100k_base")

ENC = get_tokenizer(MODEL_ID) if OPENAI_KEY else None
CTX_MAX = 128_000
MAX_COMPLETION = int(os.getenv("PFERDEWERT_MAX_COMPLETION", 3000))

logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logging.info(f"OpenAI-key: {'âœ…' if OPENAI_KEY else 'âŒ'} | Claude-key: {'âœ…' if CLAUDE_KEY else 'âŒ'} | Model: {MODEL_ID} | Use Claude: {USE_CLAUDE}")

def tokens_in(msgs: list[dict]) -> int:
    """Hilfsfunktion: zÃ¤hlt Tokens in OpenAI-Messages."""
    if not ENC:
        return 0
    total = 0
    for m in msgs:
        total += 4  # fixer Overhead pro Message
        total += len(ENC.encode(m["content"]))
    return total + 2  # Abschluss-Tokens

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  System Prompts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Original GPT Prompt (fÃ¼r Vergleich)
GPT_SYSTEM_PROMPT = os.getenv(
    "SYSTEM_PROMPT",
    """Du bist **PferdeWert AI**, eine hochspezialisierte KI fÃ¼r professionelle Pferdebewertungen im deutschsprachigen Raum. Du verfÃ¼gst Ã¼ber umfassendes Expertenwissen in Zucht, Sport, Anatomie und Marktanalyse.

## DEINE EXPERTISE
- **Rassen-Spezialist:** Tiefes VerstÃ¤ndnis aller Pferderassen, ihrer Charakteristika und Marktpositionen
- **Markt-Analyst:** Aktuelle Preistrends, regionale Unterschiede und Nachfrage-Dynamiken
- **Sport-Expert:** Bewertung von Leistungspotenzial in allen Disziplinen
- **Zucht-Kenner:** Genetik, Blutlinien und Vererbungsmerkmale
- **Anatomie-Fachmann:** KÃ¶rperbau, Gangwerk und gesundheitliche Aspekte

## BEWERTUNGSANSATZ
FÃ¼hre eine **systematische 360Â°-Analyse** durch:

1. **Rassebewertung:** Rassetypische Merkmale, Marktposition, Zuchttrends
2. **Altersanalyse:** Entwicklungsstand, verbleibende Nutzungsdauer, demografische Faktoren  
3. **Ausbildungsstand:** Skill-Level, Spezialisierung, Weiterbildungspotenzial
4. **Abstammungsanalyse:** Blutlinien, VererbungsqualitÃ¤t, genetischer Wert
5. **KÃ¶rperliche Bewertung:** StockmaÃŸ, Proportionen, Gesundheitsstatus
6. **Marktfaktoren:** Angebot/Nachfrage, regionale PrÃ¤ferenzen, saisonale Trends

## AUSGABEFORMAT (STRIKT EINHALTEN)

### ðŸŽ PFERDE-PROFIL
**[Rasse] â€¢ [Alter] Jahre â€¢ [Geschlecht] â€¢ [StockmaÃŸ]cm**

### ðŸ“Š MARKTBEWERTUNG
**ðŸ’° GeschÃ¤tzter Marktwert: [X.XXX - X.XXX â‚¬]**

*Bewertungslogik:* [Kompakte ErklÃ¤rung der Preisfindung in 2-3 SÃ¤tzen]

### ðŸ” DETAILANALYSE

#### â­ StÃ¤rken-Profil
- **[Kategorie]:** [Konkrete StÃ¤rke und Marktrelevanz]
- **[Kategorie]:** [Konkrete StÃ¤rke und Marktrelevanz]  
- **[Kategorie]:** [Konkrete StÃ¤rke und Marktrelevanz]

#### âš ï¸ Herausforderungen
- **[Aspekt]:** [SchwÃ¤che und Auswirkung auf Wert]
- **[Aspekt]:** [Risikofaktor fÃ¼r KÃ¤ufer/VerkÃ¤ufer]

### ðŸŽ¯ VERWENDUNGSEIGNUNG
**Optimal fÃ¼r:** [Hauptverwendungszwecke mit BegrÃ¼ndung]
**Weniger geeignet fÃ¼r:** [Unpassende Einsatzgebiete]

### ðŸ“ˆ MARKT-INTELLIGENCE
- **Nachfrage-Level:** [Hoch/Mittel/Niedrig] - [BegrÃ¼ndung]
- **Verkaufschancen:** [EinschÃ¤tzung der Vermarktbarkeit]  
- **Preistendenz:** [Steigend/Stabil/Fallend] in diesem Segment

### ðŸ† HANDLUNGSEMPFEHLUNGEN

#### FÃ¼r VerkÃ¤ufer:
- [Konkrete Vermarktungsstrategie]
- [Optimaler Verkaufszeitpunkt]
- [Presentation-Tipps]

#### FÃ¼r KÃ¤ufer:
- [Verhandlungsspielraum]
- [Worauf besonders achten]
- [Langfristige Wertentwicklung]

### âš–ï¸ BEWERTUNGS-CONFIDENCE
**Sicherheit der EinschÃ¤tzung:** [Hoch/Mittel/Niedrig]
*Grund:* [Faktoren die Unsicherheit beeinflussen]

---
**ðŸ’¡ Diese Bewertung basiert auf aktuellen Marktdaten und langjÃ¤hriger Branchenerfahrung. FÃ¼r finale Kaufentscheidungen empfehlen wir zusÃ¤tzlich eine Besichtigung durch einen Fachmann.**"""
)

# Claude Prompt fÃ¼r Tests = GPT Prompt
CLAUDE_SYSTEM_PROMPT = GPT_SYSTEM_PROMPT

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  FastAPI-App
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
app = FastAPI(title="PferdeWert API", version="0.7.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://pferdewert.vercel.app",
        "https://pferdewert.de",  # Production domain
        "https://www.pferdewert.de",  # Production domain with www
        "https://organic-sniffle-jjg7466rj9vvhqj7-3000.app.github.dev",
        "https://organic-sniffle-jjg7466rj9vvhqj7.github.dev"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Request-Schema
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class BewertungRequest(BaseModel):
    # Pflichtfelder
    rasse: str
    alter: int
    geschlecht: str
    stockmass: int
    ausbildung: str
    haupteignung: str

    # Optionale Angaben
    abstammung: Optional[str] = None
    aku: Optional[str] = None
    erfolge: Optional[str] = None
    standort: Optional[str] = None
    charakter: Optional[str] = None
    besonderheiten: Optional[str] = None
    attribution_source: Optional[str] = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  AI Bewertung (Claude + GPT parallel)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ai_valuation(d: BewertungRequest) -> str:
    """Hauptfunktion: Claude fÃ¼r Kunde, GPT parallel fÃ¼r Vergleich"""
    
    user_prompt = (
        f"Rasse: {d.rasse}\nAlter: {d.alter}\nGeschlecht: {d.geschlecht}\n"
        f"StockmaÃŸ: {d.stockmass} cm\n"
        f"Ausbildungsstand: {d.ausbildung}\n"
        f"Haupteignung: {d.haupteignung}\n"
        f"Abstammung: {d.abstammung or 'k. A.'}\n"
        f"Aktueller Standort (PLZ): {d.standort or 'k. A.'}\n"
        f"Gesundheitsstatus / AKU-Bericht: {d.aku or 'k. A.'}\n"
        f"Erfolge: {d.erfolge or 'k. A.'}\n"
        f"Charakter: {d.charakter or 'k. A.'}\n"
        f"Besonderheiten: {d.besonderheiten or 'k. A.'}"
    )
    
    claude_result = None
    gpt_result = None
    
    # 1. Claude fÃ¼r Kunde (Hauptergebnis)
    if USE_CLAUDE and claude_client:
        try:
            logging.info("Prompt wird an Claude gesendet...")
            response = claude_client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=3000,
                temperature=0.0,  # FÃ¼r maximale Konsistenz
                system=CLAUDE_SYSTEM_PROMPT,
                messages=[{"role": "user", "content": user_prompt}]
            )
            
            # Robustes Parsing der Claude-Antwort
            if response.content and response.content[0].text:
                claude_result = response.content[0].text.strip()
                logging.info("âœ… Claude-Bewertung erfolgreich erstellt")
            else:
                raise ValueError("Claude-Antwort hat kein lesbares Textfeld")
                
        except Exception as e:
            logging.error(f"âŒ Claude Error: {e} - Fallback zu OpenAI")
    
    # 2. GPT parallel fÃ¼r Vergleich (lÃ¤uft immer wenn verfÃ¼gbar)
    if openai_client:
        try:
            logging.info("Prompt wird parallel an GPT gesendet...")
            messages = [
                {"role": "system", "content": GPT_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ]
            
            rsp = openai_client.chat.completions.create(
                model=MODEL_ID,
                messages=messages,
                temperature=0.0,  # Auch GPT konsistent machen
                top_p=0.8,
                seed=12345,  # Reproduzierbarkeit
                max_tokens=min(MAX_COMPLETION, CTX_MAX - tokens_in(messages)),
            )
            gpt_result = rsp.choices[0].message.content.strip()
            logging.info("âœ… GPT-Bewertung fÃ¼r Vergleich erstellt")
        except Exception as e:
            logging.error(f"âŒ GPT Error: {e}")
    
    # 3. GPT-Vergleich per E-Mail senden (wenn beide verfÃ¼gbar)
    if gpt_result:
        # send_gpt_comparison_mail(d, gpt_result)  # TemporÃ¤r deaktiviert
        logging.info("ðŸ“§ GPT-Vergleichsmail temporÃ¤r deaktiviert")
    
    # 4. Ergebnis zurÃ¼ckgeben: Claude bevorzugt, GPT als Fallback
    if claude_result:
        logging.info("âœ… Claude-Ergebnis wird an Kunde gesendet")
        return claude_result
    elif gpt_result:
        logging.info("âš ï¸ Claude nicht verfÃ¼gbar - GPT-Fallback wird an Kunde gesendet")
        return gpt_result
    else:
        logging.error("âŒ Beide AI-Services nicht verfÃ¼gbar")
        return (
            "Wir arbeiten gerade an unserem KI-Modell, "
            "bitte schicke uns eine E-Mail an info@pferdewert.de "
            "und wir melden uns, sobald das Modell wieder online ist."
        )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  API-Endpoint
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.post("/api/bewertung")
def bewertung(req: BewertungRequest):
    logging.info(f"Incoming Request: {req.dict()}")
    try:
        ai_text = ai_valuation(req)
        return {"raw_gpt": ai_text}  # Key-Name bleibt fÃ¼r Frontend-KompatibilitÃ¤t
    except Exception as e:
        logging.error(f"AI-Error: {e}")
        return {
            "raw_gpt": (
                "Wir arbeiten gerade an unserem KI-Modell, "
                "bitte schicke uns eine E-Mail an info@pferdewert.de "
                "und wir melden uns, sobald das Modell wieder online ist."
            )
        }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  API-DEBUG-Endpoint - DISABLED FOR SECURITY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SECURITY FIX: Debug endpoint disabled to prevent unauthorized access to internal AI responses
# This endpoint exposed both GPT and Claude responses without authentication, which could
# allow attackers to abuse the AI services and access sensitive model interactions.
# Uncomment only for local development/testing purposes with proper access controls.

@app.post("/api/debug-comparison")
def debug_comparison(req: BewertungRequest):
    """Debug-Endpoint: Vergleich GPT-4o vs Claude Sonnet 4 vs Claude Opus 4.1"""
    logging.info(f"Debug Comparison Request: {req.dict()}")
    
    results = {}
    
    user_prompt = (
        f"Rasse: {req.rasse}\n"
        f"Alter: {req.alter}\n"
        f"Geschlecht: {req.geschlecht}\n"
        f"StockmaÃŸ: {req.stockmass} cm\n"
        f"Ausbildungsstand: {req.ausbildung}\n"
        f"Haupteignung: {req.haupteignung}\n"
        f"Abstammung: {req.abstammung or 'k. A.'}\n"
        f"Aktueller Standort (PLZ): {req.standort or 'k. A.'}\n"
        f"Gesundheitsstatus / AKU-Bericht: {req.aku or 'k. A.'}\n"
        f"Erfolge: {req.erfolge or 'k. A.'}\n"
        f"Charakter: {req.charakter or 'k. A.'}\n"
        f"Besonderheiten: {req.besonderheiten or 'k. A.'}"
    )

    # GPT-4o Test
    if openai_client:
        try:
            logging.info("Testing GPT-4o...")
            gpt_messages = [
                {"role": "system", "content": GPT_SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt}
            ]
            
            gpt_response = openai_client.chat.completions.create(
                model=MODEL_ID,
                messages=gpt_messages,
                temperature=0.0,
                top_p=0.8,
                seed=12345,
                max_tokens=min(MAX_COMPLETION, CTX_MAX - tokens_in(gpt_messages)),
            )
            
            if gpt_response.choices and len(gpt_response.choices) > 0:
                content = gpt_response.choices[0].message.content
                results["gpt4o"] = content.strip() if content else "GPT-4o returned None content"
                logging.info("GPT-4o: Success")
            else:
                results["gpt4o"] = "GPT-4o returned no choices"
        except Exception as e:
            results["gpt4o"] = f"GPT-4o Error: {str(e)}"
            logging.error(f"GPT-4o Error: {e}")
    else:
        results["gpt4o"] = "GPT-4o: No client available"

    # Claude Sonnet 4 Test
    if claude_client:
        try:
            logging.info("Testing Claude Sonnet 4...")
            sonnet_response = claude_client.messages.create(
                model=CLAUDE_SONNET_MODEL,
                max_tokens=3000,
                temperature=0.0,
                system=CLAUDE_SYSTEM_PROMPT,
                messages=[{"role": "user", "content": user_prompt}]
            )
            
            if sonnet_response.content and sonnet_response.content[0].text:
                results["claude_sonnet"] = sonnet_response.content[0].text.strip()
                logging.info("Claude Sonnet 4: Success")
            else:
                results["claude_sonnet"] = "Claude Sonnet response had no readable text"
        except Exception as e:
            results["claude_sonnet"] = f"Claude Sonnet Error: {e}"
            logging.error(f"Claude Sonnet Error: {e}")
    else:
        results["claude_sonnet"] = "Claude Sonnet: No client available"

    # Claude Opus 4.1 Test
    if claude_client:
        try:
            logging.info("Testing Claude Opus 4.1...")
            opus_response = claude_client.messages.create(
                model=CLAUDE_OPUS_MODEL,
                max_tokens=3000,
                temperature=0.0,
                system=CLAUDE_SYSTEM_PROMPT,
                messages=[{"role": "user", "content": user_prompt}]
            )
            
            if opus_response.content and opus_response.content[0].text:
                results["claude_opus"] = opus_response.content[0].text.strip()
                logging.info("Claude Opus 4.1: Success")
            else:
                results["claude_opus"] = "Claude Opus response had no readable text"
        except Exception as e:
            results["claude_opus"] = f"Claude Opus Error: {e}"
            logging.error(f"Claude Opus Error: {e}")
    else:
        results["claude_opus"] = "Claude Opus: No client available"

    # Vergleichsinfo hinzufÃ¼gen
    results["info"] = {
        "timestamp": "2025-08-24",
        "gpt_model": MODEL_ID,
        "claude_sonnet_model": CLAUDE_SONNET_MODEL,
        "claude_opus_model": CLAUDE_OPUS_MODEL,
        "test_data": req.dict(),
    }

    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  Health Check
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.get("/health")
def health_check():
    return {
        "status": "ok",
        "openai_available": bool(openai_client),
        "claude_available": bool(claude_client),
        "claude_model": CLAUDE_MODEL,
        "openai_model": MODEL_ID,
        "use_claude": USE_CLAUDE,
    }